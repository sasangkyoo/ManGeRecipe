from fastapi import FastAPI, HTTPException, Query, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import pandas as pd
import json
import glob
import os
from datetime import datetime
import uvicorn
from collections import Counter
import re

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="ë§Œê°œì˜ë ˆì‹œí”¼ API ì„œë²„",
    description="10000recipe.comì—ì„œ ìˆ˜ì§‘í•œ ë ˆì‹œí”¼ ë°ì´í„°ë¥¼ ì œê³µí•˜ëŠ” REST API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic ëª¨ë¸
class RecipeBasic(BaseModel):
    ID: str
    Title: str
    Author: str
    View: str
    Image: str

class RecipeDetail(BaseModel):
    ID: str
    Serving: str
    Preparation_Time: str
    Difficulty: str
    Ingredient: str
    Condiment: str

class RecipeFull(BaseModel):
    ID: str
    Title: str
    Author: str
    View: str
    Image: str
    Serving: str
    Preparation_Time: str
    Difficulty: str
    Ingredient: str
    Condiment: str

class SearchResponse(BaseModel):
    total_count: int
    recipes: List[RecipeFull]
    page: int
    per_page: int

class StatisticsResponse(BaseModel):
    total_recipes: int
    total_authors: int
    difficulty_distribution: Dict[str, int]
    cooking_time_distribution: Dict[str, int]
    top_ingredients: Dict[str, int]
    top_authors: Dict[str, int]

# ë°ì´í„° ë¡œë” í´ë˜ìŠ¤
class RecipeDataLoader:
    def __init__(self):
        self.food_df = None
        self.recipe_df = None
        self.merged_df = None
        self.last_loaded = None
        self.load_latest_data()
    
    def load_latest_data(self):
        """ìµœì‹  CSV íŒŒì¼ ë¡œë“œ"""
        try:
            # ìµœì‹  íŒŒì¼ ì°¾ê¸°
            food_files = glob.glob("food_data*.csv")
            recipe_files = glob.glob("recipe_data*.csv")
            
            if not food_files or not recipe_files:
                raise FileNotFoundError("CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            latest_food_file = max(food_files)
            latest_recipe_file = max(recipe_files)
            
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
            food_mtime = os.path.getmtime(latest_food_file)
            recipe_mtime = os.path.getmtime(latest_recipe_file)
            
            if (self.last_loaded is None or 
                food_mtime > self.last_loaded or 
                recipe_mtime > self.last_loaded):
                
                self.food_df = pd.read_csv(latest_food_file, encoding='utf-8-sig')
                self.recipe_df = pd.read_csv(latest_recipe_file, encoding='utf-8-sig')
                self.merged_df = pd.merge(self.food_df, self.recipe_df, on='ID', how='inner')
                self.last_loaded = max(food_mtime, recipe_mtime)
                
                print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.merged_df)}ê°œ ë ˆì‹œí”¼")
        
        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            raise
    
    def get_recipe_by_id(self, recipe_id: str) -> Optional[Dict]:
        """IDë¡œ ë ˆì‹œí”¼ ì¡°íšŒ"""
        self.load_latest_data()
        recipe = self.merged_df[self.merged_df['ID'] == recipe_id]
        if not recipe.empty:
            return recipe.iloc[0].to_dict()
        return None
    
    def search_recipes(self, 
                      query: str = "", 
                      author: str = "", 
                      difficulty: str = "",
                      max_time: int = None,
                      page: int = 1, 
                      per_page: int = 20) -> Dict:
        """ë ˆì‹œí”¼ ê²€ìƒ‰"""
        self.load_latest_data()
        
        # í•„í„°ë§
        filtered_df = self.merged_df.copy()
        
        if query:
            filtered_df = filtered_df[
                filtered_df['Title'].str.contains(query, case=False, na=False) |
                filtered_df['Ingredient'].str.contains(query, case=False, na=False)
            ]
        
        if author:
            filtered_df = filtered_df[
                filtered_df['Author'].str.contains(author, case=False, na=False)
            ]
        
        if difficulty:
            filtered_df = filtered_df[
                filtered_df['Difficulty'] == difficulty
            ]
        
        if max_time:
            # ì¡°ë¦¬ ì‹œê°„ í•„í„°ë§ (ë¶„ ë‹¨ìœ„)
            time_pattern = r'(\d+)ë¶„'
            filtered_df['time_minutes'] = filtered_df['Preparation_Time'].str.extract(time_pattern).astype(float)
            filtered_df = filtered_df[filtered_df['time_minutes'] <= max_time]
        
        # í˜ì´ì§•
        total_count = len(filtered_df)
        start_idx = (page - 1) * per_page
        end_idx = start_idx + per_page
        
        paginated_df = filtered_df.iloc[start_idx:end_idx]
        
        return {
            'total_count': total_count,
            'recipes': paginated_df.to_dict('records'),
            'page': page,
            'per_page': per_page
        }
    
    def get_statistics(self) -> Dict:
        """í†µê³„ ì •ë³´ ì¡°íšŒ"""
        self.load_latest_data()
        
        # ê¸°ë³¸ í†µê³„
        total_recipes = len(self.merged_df)
        total_authors = self.merged_df['Author'].nunique()
        
        # ë‚œì´ë„ ë¶„í¬
        difficulty_dist = self.merged_df['Difficulty'].value_counts().to_dict()
        
        # ì¡°ë¦¬ ì‹œê°„ ë¶„í¬
        time_pattern = r'(\d+)ë¶„'
        cooking_times = []
        for time_text in self.merged_df['Preparation_Time']:
            if 'ë¶„' in str(time_text):
                match = re.search(time_pattern, str(time_text))
                if match:
                    cooking_times.append(int(match.group(1)))
        
        time_dist = {
            '15ë¶„ ì´í•˜': len([t for t in cooking_times if t <= 15]),
            '15-30ë¶„': len([t for t in cooking_times if 15 < t <= 30]),
            '30-60ë¶„': len([t for t in cooking_times if 30 < t <= 60]),
            '60ë¶„ ì´ìƒ': len([t for t in cooking_times if t > 60])
        }
        
        # ìƒìœ„ ì¬ë£Œ
        ingredients = []
        for ingredient_text in self.merged_df['Ingredient']:
            if 'ì¬ë£Œ ì—†ìŒ' not in ingredient_text:
                matches = re.findall(r'[ê°€-í£]+', ingredient_text)
                ingredients.extend(matches)
        
        top_ingredients = dict(Counter(ingredients).most_common(10))
        
        # ìƒìœ„ ì‘ì„±ì
        top_authors = self.merged_df['Author'].value_counts().head(10).to_dict()
        
        return {
            'total_recipes': total_recipes,
            'total_authors': total_authors,
            'difficulty_distribution': difficulty_dist,
            'cooking_time_distribution': time_dist,
            'top_ingredients': top_ingredients,
            'top_authors': top_authors
        }
    
    def get_random_recipes(self, count: int = 10) -> List[Dict]:
        """ëœë¤ ë ˆì‹œí”¼ ì¡°íšŒ"""
        self.load_latest_data()
        return self.merged_df.sample(min(count, len(self.merged_df))).to_dict('records')
    
    def get_recipes_by_difficulty(self, difficulty: str) -> List[Dict]:
        """ë‚œì´ë„ë³„ ë ˆì‹œí”¼ ì¡°íšŒ"""
        self.load_latest_data()
        filtered_df = self.merged_df[self.merged_df['Difficulty'] == difficulty]
        return filtered_df.to_dict('records')

# ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤
data_loader = RecipeDataLoader()

# ì˜ì¡´ì„± í•¨ìˆ˜
def get_data_loader() -> RecipeDataLoader:
    return data_loader

# API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/", response_class=JSONResponse)
async def root():
    """API ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "ë§Œê°œì˜ë ˆì‹œí”¼ API ì„œë²„ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!",
        "version": "1.0.0",
        "docs": "/docs",
        "endpoints": {
            "recipes": "/recipes",
            "recipe_by_id": "/recipes/{recipe_id}",
            "search": "/search",
            "statistics": "/statistics",
            "random": "/random",
            "by_difficulty": "/difficulty/{difficulty}"
        }
    }

@app.get("/recipes", response_model=List[RecipeFull])
async def get_recipes(
    page: int = Query(1, ge=1, description="í˜ì´ì§€ ë²ˆí˜¸"),
    per_page: int = Query(20, ge=1, le=100, description="í˜ì´ì§€ë‹¹ ë ˆì‹œí”¼ ìˆ˜"),
    loader: RecipeDataLoader = Depends(get_data_loader)
):
    """ëª¨ë“  ë ˆì‹œí”¼ ì¡°íšŒ (í˜ì´ì§• ì§€ì›)"""
    try:
        start_idx = (page - 1) * per_page
        end_idx = start_idx + per_page
        
        recipes = loader.merged_df.iloc[start_idx:end_idx].to_dict('records')
        return recipes
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.get("/recipes/{recipe_id}", response_model=RecipeFull)
async def get_recipe_by_id(
    recipe_id: str,
    loader: RecipeDataLoader = Depends(get_data_loader)
):
    """IDë¡œ íŠ¹ì • ë ˆì‹œí”¼ ì¡°íšŒ"""
    recipe = loader.get_recipe_by_id(recipe_id)
    if not recipe:
        raise HTTPException(status_code=404, detail=f"ë ˆì‹œí”¼ ID {recipe_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return recipe

@app.get("/search", response_model=SearchResponse)
async def search_recipes(
    q: str = Query("", description="ê²€ìƒ‰ì–´ (ì œëª©, ì¬ë£Œ)"),
    author: str = Query("", description="ì‘ì„±ì"),
    difficulty: str = Query("", description="ë‚œì´ë„"),
    max_time: Optional[int] = Query(None, ge=1, description="ìµœëŒ€ ì¡°ë¦¬ ì‹œê°„ (ë¶„)"),
    page: int = Query(1, ge=1, description="í˜ì´ì§€ ë²ˆí˜¸"),
    per_page: int = Query(20, ge=1, le=100, description="í˜ì´ì§€ë‹¹ ë ˆì‹œí”¼ ìˆ˜"),
    loader: RecipeDataLoader = Depends(get_data_loader)
):
    """ë ˆì‹œí”¼ ê²€ìƒ‰"""
    try:
        result = loader.search_recipes(
            query=q,
            author=author,
            difficulty=difficulty,
            max_time=max_time,
            page=page,
            per_page=per_page
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")

@app.get("/statistics", response_model=StatisticsResponse)
async def get_statistics(
    loader: RecipeDataLoader = Depends(get_data_loader)
):
    """í†µê³„ ì •ë³´ ì¡°íšŒ"""
    try:
        return loader.get_statistics()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.get("/random", response_model=List[RecipeFull])
async def get_random_recipes(
    count: int = Query(10, ge=1, le=50, description="ëœë¤ ë ˆì‹œí”¼ ìˆ˜"),
    loader: RecipeDataLoader = Depends(get_data_loader)
):
    """ëœë¤ ë ˆì‹œí”¼ ì¡°íšŒ"""
    try:
        return loader.get_random_recipes(count)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ëœë¤ ë ˆì‹œí”¼ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.get("/difficulty/{difficulty}", response_model=List[RecipeFull])
async def get_recipes_by_difficulty(
    difficulty: str,
    loader: RecipeDataLoader = Depends(get_data_loader)
):
    """ë‚œì´ë„ë³„ ë ˆì‹œí”¼ ì¡°íšŒ"""
    try:
        recipes = loader.get_recipes_by_difficulty(difficulty)
        if not recipes:
            raise HTTPException(status_code=404, detail=f"ë‚œì´ë„ '{difficulty}'ì˜ ë ˆì‹œí”¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return recipes
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë‚œì´ë„ë³„ ë ˆì‹œí”¼ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/download/csv")
async def download_csv():
    """ìµœì‹  CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        food_files = glob.glob("food_data*.csv")
        recipe_files = glob.glob("recipe_data*.csv")
        
        if not food_files or not recipe_files:
            raise HTTPException(status_code=404, detail="CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        latest_food_file = max(food_files)
        return FileResponse(
            latest_food_file,
            media_type='text/csv',
            filename=f"recipes_{datetime.now().strftime('%Y%m%d')}.csv"
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {str(e)}")

# ì—ëŸ¬ í•¸ë“¤ëŸ¬
@app.exception_handler(404)
async def not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={"detail": "ìš”ì²­í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    )

@app.exception_handler(500)
async def internal_error_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={"detail": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}
    )

if __name__ == "__main__":
    print("ğŸš€ ë§Œê°œì˜ë ˆì‹œí”¼ API ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ğŸ” ReDoc ë¬¸ì„œ: http://localhost:8000/redoc")
    print("ğŸŒ API ë£¨íŠ¸: http://localhost:8000/")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 